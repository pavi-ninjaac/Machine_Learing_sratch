{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import make_regression\n\nfrom sklearn.metrics import r2_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-27T14:41:54.900631Z","iopub.execute_input":"2024-02-27T14:41:54.901045Z","iopub.status.idle":"2024-02-27T14:41:56.064573Z","shell.execute_reply.started":"2024-02-27T14:41:54.900934Z","shell.execute_reply":"2024-02-27T14:41:56.063450Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class LinearRegression:\n    def __init__(self, learning_rate, iteration):\n        \"\"\"\n        :param learning_rate: A samll value needed for gradient decent, default value id 0.1.\n        :param iteration: Number of training iteration, default value is 10,000.\n        \"\"\"\n        self.m = None\n        self.n = None\n        self.w = None\n        self.lr = learning_rate\n        self.it = iteration\n\n    def cost_function(self, y, y_pred):\n        \"\"\"\n        :param y: Original target value.\n        :param y_pred: predicted target value.\n        \"\"\"\n        return (1 / (2*self.m)) * np.sum(np.square(y_pred - y))\n    \n    def hypothesis(self, weights, X):\n        \"\"\"\n        :param weights: parameter value weight.\n        :param X: Training samples.\n        \"\"\"\n        return np.dot(X, weights)\n\n    def train(self, X, y):\n        \"\"\"\n        :param X: training data feature values ---> N Dimentional vector.\n        :param y: training data target value -----> 1 Dimentional array.\n        \"\"\"\n        # Insert constant ones for bias weights.\n        X = np.insert(X, 0, 1, axis=1)\n        # Target value should be in the shape of (n, 1) not (n, ).\n        # So, this will check that and change the shape to (n, 1), if not.\n        try:\n            y.shape[1]\n        except IndexError as e:\n            # we need to change it to the 1 D array, not a list.\n            print(\"ERROR: Target array should be a one dimentional array not a list\"\n                  \"----> here the target value not in the shape of (n,1). \\nShape ({shape_y_0},1) and {shape_y} not match\"\n                  .format(shape_y_0 = y.shape[0] , shape_y = y.shape))\n            return \n        \n        # m is the number of training samples.\n        self.m = X.shape[0]\n        # n is the number of features.\n        self.n = X.shape[1]\n\n        # Set the initial weight.\n        self.w = np.zeros((self.n , 1))\n\n        for it in range(1, self.it+1):\n            # 1. Find the predicted value through the hypothesis.\n            # 2. Find the Cost function value.\n            # 3. Find the derivation of weights.\n            # 4. Apply Gradient Decent.\n            y_pred = self.hypothesis(self.w, X)\n\n            cost = self.cost_function(y, y_pred)\n            # fin the derivative.\n            dw = (1/self.m) * np.dot(X.T, (y_pred - y))\n\n            # change the weight parameter.\n            self.w = self.w - self.lr * dw\n\n            if it % 1000 == 0:\n                print(\"The Cost function for the iteration {}----->{} :)\".format(it, cost))\n    def predict(self, test_X):\n        \"\"\"\n        :param test_X: feature values to predict.\n        \"\"\"\n        # Insert constant ones for bias weights\n        test_X = np.insert(test_X, 0, 1, axis=1)\n        y_pred = self.hypothesis(self.w, test_X)\n        return y_pred\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:41:56.067130Z","iopub.execute_input":"2024-02-27T14:41:56.067677Z","iopub.status.idle":"2024-02-27T14:41:56.087027Z","shell.execute_reply.started":"2024-02-27T14:41:56.067618Z","shell.execute_reply":"2024-02-27T14:41:56.085937Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define the traning data.\nX, y = make_regression(n_samples=50000, n_features=8)\n\n# Chnage the shape of the target to 1 dimentional array.\ny = y[:, np.newaxis]\n\nprint(\"=\"*100)\nprint(\"Number of training data samples-----> {}\".format(X.shape[0]))\nprint(\"Number of training features --------> {}\".format(X.shape[1]))\nprint(\"Shape of the target value ----------> {}\".format(y.shape))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:41:56.088348Z","iopub.execute_input":"2024-02-27T14:41:56.088619Z","iopub.status.idle":"2024-02-27T14:41:56.160361Z","shell.execute_reply.started":"2024-02-27T14:41:56.088586Z","shell.execute_reply":"2024-02-27T14:41:56.155182Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"====================================================================================================\nNumber of training data samples-----> 50000\nNumber of training features --------> 8\nShape of the target value ----------> (50000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# display the data.\ndata = pd.DataFrame(X)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:41:56.165385Z","iopub.execute_input":"2024-02-27T14:41:56.166939Z","iopub.status.idle":"2024-02-27T14:41:56.218191Z","shell.execute_reply.started":"2024-02-27T14:41:56.166843Z","shell.execute_reply":"2024-02-27T14:41:56.216956Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6  \\\n0  0.754571 -0.083893 -0.373653 -1.358137 -0.200176  0.429999 -1.694845   \n1  0.684339  0.555229  0.013751 -0.774771  0.476398  0.111331 -0.363848   \n2  1.489315 -0.960178  0.111806 -0.029635  0.230680 -0.444842 -1.369935   \n3 -0.246996  0.052014 -0.168797  0.685601  1.331316 -0.158850 -0.799387   \n4 -1.119003  1.706002 -0.460947  1.461523  1.323132 -1.215560 -0.641541   \n\n          7  \n0 -0.870411  \n1 -1.932533  \n2  1.733601  \n3 -0.165396  \n4 -1.294358  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.754571</td>\n      <td>-0.083893</td>\n      <td>-0.373653</td>\n      <td>-1.358137</td>\n      <td>-0.200176</td>\n      <td>0.429999</td>\n      <td>-1.694845</td>\n      <td>-0.870411</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.684339</td>\n      <td>0.555229</td>\n      <td>0.013751</td>\n      <td>-0.774771</td>\n      <td>0.476398</td>\n      <td>0.111331</td>\n      <td>-0.363848</td>\n      <td>-1.932533</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.489315</td>\n      <td>-0.960178</td>\n      <td>0.111806</td>\n      <td>-0.029635</td>\n      <td>0.230680</td>\n      <td>-0.444842</td>\n      <td>-1.369935</td>\n      <td>1.733601</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.246996</td>\n      <td>0.052014</td>\n      <td>-0.168797</td>\n      <td>0.685601</td>\n      <td>1.331316</td>\n      <td>-0.158850</td>\n      <td>-0.799387</td>\n      <td>-0.165396</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.119003</td>\n      <td>1.706002</td>\n      <td>-0.460947</td>\n      <td>1.461523</td>\n      <td>1.323132</td>\n      <td>-1.215560</td>\n      <td>-0.641541</td>\n      <td>-1.294358</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# display the data.\ndata_y = pd.DataFrame(y)\ndata_y.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:41:56.225065Z","iopub.execute_input":"2024-02-27T14:41:56.229190Z","iopub.status.idle":"2024-02-27T14:41:56.245418Z","shell.execute_reply.started":"2024-02-27T14:41:56.229112Z","shell.execute_reply":"2024-02-27T14:41:56.244406Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"           0\n0 -55.386910\n1   6.618750\n2 -27.359438\n3  24.875382\n4  29.718823","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-55.386910</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.618750</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-27.359438</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24.875382</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.718823</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#define the parameters\nparam = {\n    \"learning_rate\" : 0.1,\n    \"iteration\" : 10000\n}\nprint(\"=\"*100)\nlinear_reg = LinearRegression(**param)\n\n# Train the model.\nlinear_reg.train(X, y) \n\n# Predict the values.\ny_pred = linear_reg.predict(X)\n\n#Root mean square error.\nscore = r2_score(y, y_pred)\nprint(\"The r2_score of the trained model\", score)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:41:56.246655Z","iopub.execute_input":"2024-02-27T14:41:56.247449Z","iopub.status.idle":"2024-02-27T14:42:03.710631Z","shell.execute_reply.started":"2024-02-27T14:41:56.247412Z","shell.execute_reply":"2024-02-27T14:42:03.709498Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"====================================================================================================\nThe Cost function for the iteration 1000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 2000----->5.4946124452301445e-27 :)\nThe Cost function for the iteration 3000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 4000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 5000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 6000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 7000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 8000----->5.494614969585041e-27 :)\nThe Cost function for the iteration 9000----->5.4946124452301445e-27 :)\nThe Cost function for the iteration 10000----->5.494614969585041e-27 :)\nThe r2_score of the trained model 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Lienar Regression using Skicit-Learn","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression as LinearRegression_sklearn\nfrom sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:42:03.712539Z","iopub.execute_input":"2024-02-27T14:42:03.713189Z","iopub.status.idle":"2024-02-27T14:42:03.836259Z","shell.execute_reply.started":"2024-02-27T14:42:03.713128Z","shell.execute_reply":"2024-02-27T14:42:03.835409Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# data is already defined, going to use the same data for comparision.\nprint(\"=\"*100)\nprint(\"Number of training data samples-----> {}\".format(X.shape[0]))\nprint(\"Number of training features --------> {}\".format(X.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:42:03.840600Z","iopub.execute_input":"2024-02-27T14:42:03.842655Z","iopub.status.idle":"2024-02-27T14:42:03.850947Z","shell.execute_reply.started":"2024-02-27T14:42:03.842609Z","shell.execute_reply":"2024-02-27T14:42:03.849994Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"====================================================================================================\nNumber of training data samples-----> 50000\nNumber of training features --------> 8\n","output_type":"stream"}]},{"cell_type":"code","source":"linear_reg_sklearn = LinearRegression_sklearn()\nlinear_reg_sklearn.fit(X, y)\n\n# predict the value\ny_pred_sklearn = linear_reg_sklearn.predict(X)\nscore = r2_score(y, y_pred_sklearn)\nprint(\"=\"*100)\nprint(\"R2 score of the model is {}\".format(score))","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:42:03.852689Z","iopub.execute_input":"2024-02-27T14:42:03.853083Z","iopub.status.idle":"2024-02-27T14:42:03.905915Z","shell.execute_reply.started":"2024-02-27T14:42:03.853037Z","shell.execute_reply":"2024-02-27T14:42:03.904776Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"====================================================================================================\nR2 score of the model is 1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Conclution:\n# Our model works well as the scikit learn on speed and accuracy.","metadata":{"execution":{"iopub.status.busy":"2024-02-27T14:42:03.909686Z","iopub.execute_input":"2024-02-27T14:42:03.913232Z","iopub.status.idle":"2024-02-27T14:42:03.919436Z","shell.execute_reply.started":"2024-02-27T14:42:03.913170Z","shell.execute_reply":"2024-02-27T14:42:03.918151Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}